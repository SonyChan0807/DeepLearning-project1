{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dlc_bci as bci\n",
    "from dlc_practical_prologue import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "tr_input, tr_target = bci.load(\"bci\", train=True, one_khz=False)\n",
    "te_input, te_target = bci.load(\"bci\", train=False, one_khz=False)\n",
    "\n",
    "# Prepare onehot vector for computation of loss\n",
    "tr_target_onehot = convert_to_one_hot_labels(tr_input, tr_target)\n",
    "te_target_onehot = convert_to_one_hot_labels(te_input, te_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "tr_input = torch.nn.functional.normalize(tr_input, p=2, dim=0) \n",
    "te_input = torch.nn.functional.normalize(te_input, p=2, dim=0) \n",
    "\n",
    "# Convert to 4D tensor [dataset size, number of channels, rows, cols]\n",
    "tr_input = tr_input[:, np.newaxis, :, :]\n",
    "te_input = te_input[:, np.newaxis, :, :]\n",
    "\n",
    "# Convert to pytorch variable\n",
    "tr_input, tr_target, tr_target_onehot = Variable(tr_input), Variable(tr_target), Variable(tr_target_onehot)\n",
    "te_input, te_target, te_target_onehot = Variable(te_input), Variable(te_target), Variable(te_target_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of NN is still a vector (cross entropy loss handles log-softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1a = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(28, 5), stride=2)\n",
    "        self.conv1b = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(28, 10), stride=2)\n",
    "        self.conv1c = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(28, 15), stride=2)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(1, 5), stride=2)\n",
    "        self.conv2b = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(1, 10), stride=2)\n",
    "        self.conv2c = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(1, 15), stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(346, 200)\n",
    "        self.fc2 = nn.Linear(200, 2)\n",
    "        \n",
    "    def forward(self, x, mode=False):\n",
    "        \n",
    "        # convolve\n",
    "        x1a = self.conv1a(x)\n",
    "        x1b = self.conv1b(x)\n",
    "        x1c = self.conv1c(x)\n",
    "        \n",
    "        # reshape and concat\n",
    "        x = torch.cat((x1a.view(x1a.size(0), -1), x1b.view(x1b.size(0), -1), x1c.view(x1c.size(0), -1)), 1)    \n",
    "        x = x.view(x.size(0), 1, 1,-1)\n",
    "        \n",
    "        # convolve\n",
    "        x2a = self.conv2a(x)\n",
    "        x2b = self.conv2b(x)\n",
    "        x2c = self.conv2c(x)\n",
    "        \n",
    "        x = torch.cat((x2a.view(x2a.size(0), -1), x2b.view(x2b.size(0), -1), x2c.view(x2c.size(0), -1)), 1)\n",
    "        \n",
    "        # fc\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=mode)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 tr loss 55.48 te loss 17.68\n",
      "epoch 1 tr loss 55.54 te loss 17.43\n",
      "epoch 2 tr loss 55.15 te loss 17.42\n",
      "epoch 3 tr loss 55.24 te loss 17.39\n",
      "epoch 4 tr loss 55.18 te loss 17.39\n",
      "epoch 5 tr loss 55.08 te loss 17.38\n",
      "epoch 6 tr loss 55.03 te loss 17.38\n",
      "epoch 7 tr loss 55.00 te loss 17.38\n",
      "epoch 8 tr loss 55.04 te loss 17.38\n",
      "epoch 9 tr loss 55.02 te loss 17.38\n",
      "epoch 10 tr loss 55.02 te loss 17.38\n",
      "epoch 11 tr loss 55.05 te loss 17.38\n",
      "epoch 12 tr loss 54.99 te loss 17.39\n",
      "epoch 13 tr loss 55.04 te loss 17.38\n",
      "epoch 14 tr loss 54.99 te loss 17.37\n",
      "epoch 15 tr loss 54.81 te loss 17.39\n",
      "epoch 16 tr loss 54.92 te loss 17.38\n",
      "epoch 17 tr loss 54.97 te loss 17.40\n",
      "epoch 18 tr loss 54.76 te loss 17.40\n",
      "epoch 19 tr loss 54.82 te loss 17.42\n",
      "epoch 20 tr loss 54.81 te loss 17.39\n",
      "epoch 21 tr loss 54.48 te loss 17.48\n",
      "epoch 22 tr loss 54.43 te loss 17.49\n",
      "epoch 23 tr loss 54.43 te loss 17.55\n",
      "epoch 24 tr loss 54.30 te loss 17.69\n",
      "epoch 25 tr loss 54.39 te loss 17.75\n",
      "epoch 26 tr loss 53.92 te loss 17.82\n",
      "epoch 27 tr loss 54.00 te loss 17.66\n",
      "epoch 28 tr loss 53.56 te loss 17.80\n",
      "epoch 29 tr loss 53.51 te loss 17.91\n",
      "epoch 30 tr loss 53.02 te loss 18.31\n",
      "epoch 31 tr loss 53.87 te loss 17.92\n",
      "epoch 32 tr loss 52.41 te loss 18.13\n",
      "epoch 33 tr loss 52.50 te loss 17.78\n",
      "epoch 34 tr loss 52.11 te loss 18.39\n",
      "epoch 35 tr loss 52.25 te loss 18.08\n",
      "epoch 36 tr loss 50.22 te loss 17.71\n",
      "epoch 37 tr loss 49.79 te loss 17.62\n",
      "epoch 38 tr loss 48.69 te loss 17.54\n",
      "epoch 39 tr loss 47.21 te loss 17.30\n",
      "epoch 40 tr loss 45.71 te loss 16.52\n",
      "epoch 41 tr loss 43.74 te loss 17.09\n",
      "epoch 42 tr loss 43.54 te loss 14.97\n",
      "epoch 43 tr loss 41.12 te loss 15.08\n",
      "epoch 44 tr loss 39.58 te loss 16.56\n",
      "epoch 45 tr loss 39.45 te loss 17.26\n",
      "epoch 46 tr loss 37.28 te loss 15.87\n",
      "epoch 47 tr loss 37.04 te loss 15.10\n",
      "epoch 48 tr loss 36.30 te loss 15.64\n",
      "epoch 49 tr loss 35.48 te loss 15.34\n",
      "tr error 17.09% 54/316\n",
      "te error 26.00% 26/100\n"
     ]
    }
   ],
   "source": [
    "# construct and train model\n",
    "model = Net()\n",
    "tr_loss, te_loss = bci.train_model(model, tr_input, tr_target, 4, te_input, te_target, 4, 50)\n",
    "#torch.save(model.state_dict(), os.getcwd() + \"v1.pth\")\n",
    "\n",
    "# compute train and test errors\n",
    "nb_tr_errors = bci.compute_nb_errors(model, tr_input, tr_target_onehot, 4)\n",
    "nb_te_errors = bci.compute_nb_errors(model, te_input, te_target_onehot, 4)\n",
    "\n",
    "print('tr error {:0.2f}% {:d}/{:d}'.format((100 * nb_tr_errors) / tr_input.size(0), nb_tr_errors, tr_input.size(0)))\n",
    "print('te error {:0.2f}% {:d}/{:d}'.format((100 * nb_te_errors) / te_input.size(0), nb_te_errors, te_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tr_loss, label='training loss')\n",
    "plt.plot(te_loss, label='validation loss')\n",
    "plt.legend(loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
